{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Kickstarter Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\r\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\r\n",
    "\r\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define function for ttraining and testing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def fittest(X_train, X_test, y_train, y_test, estimator, scaler=None):\r\n",
    "\r\n",
    "    if scaler != None:\r\n",
    "        scaler.fit(X_train)\r\n",
    "        X_train_scaled = scaler.transform(X_train)\r\n",
    "        X_test_scaled = scaler.transform(X_test)\r\n",
    "    else:\r\n",
    "        X_train_scaled = X_train\r\n",
    "        X_test_scaled = X_test\r\n",
    "\r\n",
    "    estimator.fit(X_train_scaled, y_train)\r\n",
    "    \r\n",
    "    y_pred = estimator.predict(X_test_scaled) \r\n",
    "    y_train_pred = estimator.predict(X_train_scaled) \r\n",
    "    \r\n",
    "    return {'cm_test':confusion_matrix(y_test, y_pred), \r\n",
    "            'ac_test':accuracy_score(y_test, y_pred),\r\n",
    "            'rc_test':recall_score(y_test, y_pred),\r\n",
    "            'pr_test':precision_score(y_test, y_pred),\r\n",
    "            'f1_test':f1_score(y_test, y_pred),\r\n",
    "            'ra_test':roc_auc_score(y_test, y_pred), \r\n",
    "            'pred':y_pred,\r\n",
    "            #'proba':estimator.predict_proba(X_test_scaled),\r\n",
    "            'cm_train':confusion_matrix(y_train, y_train_pred), \r\n",
    "            'ac_train':accuracy_score(y_train, y_train_pred),\r\n",
    "            'rc_train':recall_score(y_train, y_train_pred),\r\n",
    "            'pr_train':precision_score(y_train, y_train_pred),\r\n",
    "            'f1_train':f1_score(y_train, y_train_pred),\r\n",
    "            'ra_train':roc_auc_score(y_train, y_train_pred)}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv('../data/kickstarter_cleaned.csv')\r\n",
    "print(df.shape)\r\n",
    "print(df.columns)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(18124, 11)\n",
      "Index(['country', 'goal', 'state', 'cat_id', 'location_type', 'location_score',\n",
      "       'delta_funding', 'name_length', 'name_words', 'projects_successful',\n",
      "       'projects_failed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Turn `successful` and `failed` into 1 and 0, respectively, and check feature balance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.state.replace({'successful':1, 'failed':0}, inplace=True)\r\n",
    "df.state.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    15914\n",
       "0     2210\n",
       "Name: state, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Turn datetime columns into datetime format and extract features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df.created_at = df.created_at.astype('datetime64')\r\n",
    "df.launched_at = df.launched_at.astype('datetime64')\r\n",
    "df.deadline = df.deadline.astype('datetime64')\r\n",
    "\r\n",
    "df['month_created'] = df['created_at'].dt.month\r\n",
    "df['month_launched'] = df['launched_at'].dt.month\r\n",
    "df['month_deadline'] = df['deadline'].dt.month\r\n",
    "\r\n",
    "df['delta_public'] = (df['created_at'] - df['launched_at']) / pd.offsets.Day(-1)\r\n",
    "df['delta_funding'] = (df['launched_at'] - df['deadline']) / pd.offsets.Day(-1)\r\n",
    "\r\n",
    "df['delta_total'] = ((df['created_at'] - df['deadline']) / pd.offsets.Day(-1)).round(0)\r\n",
    "\r\n",
    "df['delta_public'] = df.delta_public.round(0)\r\n",
    "df['delta_funding'] = df.delta_funding.round(0)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'created_at'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9640/1755250515.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datetime64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunched_at\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunched_at\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datetime64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeadline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeadline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datetime64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'month_created'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'created_at'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'created_at'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Correlations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df[['location_score', 'gender', 'delta_public',\r\n",
    "    #'blurb_length', 'blurb_words', 'blurb_?', 'blurb_.', 'blurb_,', 'blurb_;', 'blurb_pm', 'blurb_mwl',\r\n",
    "    #'name_length', 'name_words', \r\n",
    "    'projects_successful', 'projects_failed',\r\n",
    "    'state']].corr('pearson')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select features to be used in the model and sort them into numerical, categorical, time. Dummify the categorical features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "feat_num = ['goal', \r\n",
    "            #'blurb_length', 'blurb_words', 'blurb_!', 'blurb_?', 'blurb_.', 'blurb_,', 'blurb_;', \r\n",
    "            'name_length', 'name_words', \r\n",
    "            'projects_successful', 'projects_failed', 'location_score'\r\n",
    "           ]\r\n",
    "feat_cat = ['country', 'cat_id'#, 'location_state', 'gender'\r\n",
    "           ]\r\n",
    "feat_time = [#'month_created', 'month_launched', 'month_deadline', 'delta_public', \r\n",
    "             'delta_funding']\r\n",
    "\r\n",
    "X = df[feat_num+feat_cat+feat_time]\r\n",
    "y = df.state\r\n",
    "\r\n",
    "X = pd.get_dummies(X, columns=feat_cat, drop_first=True)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shape"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(170070, 180)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train-test split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate scalers and classifiers to be studied."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ss = StandardScaler()\r\n",
    "mm = MinMaxScaler()\r\n",
    "lr = LogisticRegression(C = 10, max_iter=1000, random_state=1)\r\n",
    "nb = GaussianNB()\r\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_features='sqrt', max_depth=15, min_samples_leaf=10)\r\n",
    "ad = AdaBoostClassifier(base_estimator=LogisticRegression(), random_state=1, n_estimators=500, learning_rate=.5)\r\n",
    "sv = SVC()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train and check performance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = datetime.now()\r\n",
    "lr_ss = fittest(X_train, X_test, y_train, y_test, lr, ss)\r\n",
    "print(format(datetime.now()-start))\r\n",
    "lr_ss"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:00:03.199896\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = datetime.now()\r\n",
    "lr_mm = fittest(X_train, X_test, y_train, y_test, lr, mm)\r\n",
    "print(format(datetime.now()-start))\r\n",
    "lr_mm"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:00:15.350423\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = datetime.now()\r\n",
    "nb_ss = fittest(X_train, X_test, y_train, y_test, nb, ss)\r\n",
    "print(format(datetime.now()-start))\r\n",
    "nb_ss"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:00:02.450005\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = datetime.now()\r\n",
    "nb_mm = fittest(X_train, X_test, y_train, y_test, nb, mm)\r\n",
    "print(format(datetime.now()-start))\r\n",
    "nb_mm"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:00:02.205504\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = datetime.now()\r\n",
    "rf_ss = fittest(X_train, X_test, y_train, y_test, rf, ss)\r\n",
    "print(format(datetime.now()-start))\r\n",
    "rf_ss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = datetime.now()\r\n",
    "rf_mm = fittest(X_train, X_test, y_train, y_test, rf, mm)\r\n",
    "print(format(datetime.now()-start))\r\n",
    "rf_mm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = datetime.now()\r\n",
    "ad_ss = fittest(X_train, X_test, y_train, y_test, ad, ss)\r\n",
    "print(format(datetime.now()-start))\r\n",
    "ad_ss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = datetime.now()\r\n",
    "ad_mm = fittest(X_train, X_test, y_train, y_test, ad, mm)\r\n",
    "print(format(datetime.now()-start))\r\n",
    "ad_mm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = datetime.now()\r\n",
    "sv_ss = fittest(X_train, X_test, y_train, y_test, sv, ss)\r\n",
    "print(format(datetime.now()-start))\r\n",
    "sv_ss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = datetime.now()\r\n",
    "sv_mm = fittest(X_train, X_test, y_train, y_test, sv, mm)\r\n",
    "print(format(datetime.now()-start))\r\n",
    "sv_mm"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:00:00.000069\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experimental\r\n",
    "\r\n",
    "Try to blend classifiers to improve accuracy of prediction (work in progress)-"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#ad_ss_pred = ad_ss['pred']\r\n",
    "#ad_mm_pred = ad_mm['pred']\r\n",
    "lr_ss_pred = lr_ss['pred']\r\n",
    "lr_mm_pred = lr_mm['pred']\r\n",
    "#rf_ss_pred = rf_ss['pred']\r\n",
    "#rf_mm_pred = rf_mm['pred']\r\n",
    "nb_ss_pred = nb_ss['pred']\r\n",
    "nb_mm_pred = nb_mm['pred']\r\n",
    "#sv_ss_pred = rf_ss['pred']\r\n",
    "#sv_mm_pred = rf_mm['pred']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# total coincidence test-pred \r\n",
    "d = len([i for i in range(len(y_test)) if \r\n",
    "               #y_test.iloc[i] != ad_ss_pred[i] and \r\n",
    "               y_test.iloc[i] != lr_ss_pred[i] and \r\n",
    "               y_test.iloc[i] != lr_mm_pred[i] and \r\n",
    "               #y_test.iloc[i] != rf_ss_pred[i] and \r\n",
    "               #y_test.iloc[i] != rf_mm_pred[i] and \r\n",
    "               y_test.iloc[i] != nb_ss_pred[i] \r\n",
    "               and y_test.iloc[i] != nb_mm_pred[i]\r\n",
    "              ])\r\n",
    "# individual coincidences ss-mm\r\n",
    "#d_ad_ss_mm = len([i for i in range(len(y_test)) if ad_ss_pred[i] != ad_mm_pred[i]])\r\n",
    "d_lr_ss_mm = len([i for i in range(len(y_test)) if lr_ss_pred[i] != lr_mm_pred[i]])\r\n",
    "d_nb_ss_mm = len([i for i in range(len(y_test)) if nb_ss_pred[i] != nb_mm_pred[i]])\r\n",
    "#d_rf_ss_mm = len([i for i in range(len(y_test)) if rf_ss_pred[i] != rf_mm_pred[i]])\r\n",
    "#d_sv_ss_mm = len([i for i in range(len(y_test)) if sv_ss_pred[i] != sv_mm_pred[i]])\r\n",
    "\r\n",
    "d, d_lr_ss_mm, d_nb_ss_mm"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5143, 134, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "blend_proba = (0*lr_ss['proba'][:,1] + 100*ad_ss['proba'][:,1] + nb_ss['proba'][:,1])/101\r\n",
    "y_pred_blend = [int(x > .5) for x in blend_proba]\r\n",
    "\r\n",
    "print(confusion_matrix(y_test, y_pred_blend))\r\n",
    "print(accuracy_score(y_test, y_pred_blend))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[18442    58]\n",
      " [14420  9598]]\n",
      "0.6594853944211864\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Observations / Todo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- (Y) add time deltas and keep only `launched_at`\n",
    "- (N) add blurb length as numerical feature: no improvement\n",
    "- (Y) add name length and name word count: helps\n",
    "- (Y) analyze effect of cities: extract state in US\n",
    "- (Y) Fine categorization performs much better than just category_parent_id\n",
    "- (N) Categorization performs much better than cat_score\n",
    "- (?) Compare location --> state with location_score"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit (windows store)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "dd0b763ea4d3b776545a241ed25522670db6da5a93a666ab3f023d4cd54230bc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}